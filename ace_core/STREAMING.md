# Streaming Response - ACE Framework

## ğŸ¯ Overview

ACE Framework há»— trá»£ **streaming response** Ä‘á»ƒ cáº£i thiá»‡n tráº£i nghiá»‡m ngÆ°á»i dÃ¹ng.

## âœ¨ Features

### Request-Response (Non-Streaming)
```python
result = await ace.process_query(query)
# Wait for complete response
print(result)
```

### Streaming
```python
async for chunk in ace.process_query_stream(query):
    print(chunk, end='', flush=True)
# Response appears token by token
```

## ğŸ”§ Implementation

### OllamaClient Streaming

```python
async def generate_stream(self, prompt: str):
    """Generate streaming response"""
    payload = {
        "model": self.config.model,
        "prompt": prompt,
        "stream": True  # Enable streaming
    }
    
    async with self.session.post(...) as resp:
        async for line in resp.content:
            data = json.loads(line)
            if 'response' in data:
                yield Success(data['response'])
```

### ACEFramework Streaming

```python
async def process_query_stream(self, query: str):
    """Process with streaming"""
    full_response = ""
    
    # Stream to user
    async for result in self.client.generate_stream(prompt):
        match result:
            case Success(chunk):
                full_response += chunk
                yield chunk  # Stream to user
    
    # Learn from complete response
    trajectory = parse_trajectory_response(query, full_response)
    insights = await self.reflector.reflect(trajectory)
    self.curator.apply_delta(insights)
```

## ğŸ“Š Benefits

âœ… **Better UX** - User sees response immediately
âœ… **Perceived Speed** - Feels faster than waiting
âœ… **Real-time Feedback** - Token-by-token display
âœ… **Functional** - Still maintains pure functions for learning

## ğŸš€ Usage

### Interactive Mode
```bash
python main.py

ğŸ‘¤ You: Hello
ğŸ¤– ACE:
Hello! How can I assist you today?
ğŸ’¡ Context: 1 bullets learned
```

### Demo Mode
```bash
python main.py demo

ğŸ¤– Response:
STEPS: [analyze; plan; execute]
OUTCOME: Complete answer here
SUCCESS: true
```

## ğŸ“ Architecture

```
User Query
    â†“
[Stream to User] â† OllamaClient.generate_stream()
    â†“              (token by token)
Full Response
    â†“
[Learn] â†’ Parse â†’ Reflect â†’ Curate
    â†“
Context Updated
```

**Streaming for UX, Pure Functions for Learning!** ğŸš€
